{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU4V-twNeNA-",
        "outputId": "694ab31f-23a7-4c30-c3c1-3369f5b36b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torch-2.4.0.dev20240420%2Bcu121-cp310-cp310-linux_x86_64.whl (795.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m795.4/795.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m959.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-triton==3.0.0+989adb9a29 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.0.0%2B989adb9a29-cp310-cp310-linux_x86_64.whl (236.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: pytorch-triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.4.0.dev20240420+cu121 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.4.0.dev20240420+cu121 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.4.0.dev20240420+cu121 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.4.0.dev20240420+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pytorch-triton-3.0.0+989adb9a29 torch-2.4.0.dev20240420+cu121\n",
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Collecting fbgemm_gpu\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/fbgemm_gpu-2024.4.20%2Bcu121-cp310-cp310-manylinux2014_x86_64.whl (208.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fbgemm_gpu) (1.25.2)\n",
            "Installing collected packages: fbgemm_gpu\n",
            "Successfully installed fbgemm_gpu-2024.4.20+cu121\n",
            "Collecting torchmetrics==1.0.3\n",
            "  Downloading torchmetrics-1.0.3-py3-none-any.whl (731 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3) (2.4.0.dev20240420+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3) (24.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from torchmetrics==1.0.3)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.7.0->torchmetrics==1.0.3) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.7.0->torchmetrics==1.0.3) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (12.1.105)\n",
            "Requirement already satisfied: pytorch-triton==3.0.0+989adb9a29 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3) (3.0.0+989adb9a29)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->torchmetrics==1.0.3) (12.1.105)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.0.3) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==1.0.3) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 torchmetrics-1.0.3\n",
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Collecting torchrec\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchrec-0.8.0.dev20240420%2Bcu121-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.8/486.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fbgemm-gpu in /usr/local/lib/python3.10/dist-packages (from torchrec) (2024.4.20+cu121)\n",
            "Requirement already satisfied: torchmetrics==1.0.3 in /usr/local/lib/python3.10/dist-packages (from torchrec) (1.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchrec) (4.66.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3->torchrec) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3->torchrec) (2.4.0.dev20240420+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3->torchrec) (24.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==1.0.3->torchrec) (0.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.7.0->torchmetrics==1.0.3->torchrec) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.7.0->torchmetrics==1.0.3->torchrec) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.105)\n",
            "Requirement already satisfied: pytorch-triton==3.0.0+989adb9a29 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==1.0.3->torchrec) (3.0.0+989adb9a29)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->torchmetrics==1.0.3->torchrec) (12.1.105)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.0.3->torchrec) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==1.0.3->torchrec) (1.3.0)\n",
            "Installing collected packages: torchrec\n",
            "Successfully installed torchrec-0.8.0.dev20240420+cu121\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121 -U\n",
        "!pip3 install fbgemm_gpu --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "!pip3 install torchmetrics==1.0.3\n",
        "!pip3 install torchrec --index-url https://download.pytorch.org/whl/nightly/cu121"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torchrec\n",
        "import torch.distributed as dist\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "Wf-Tp0-zekc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchrec\n",
        "import torch.distributed as dist\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "qQ_TbTG6ePmT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/ratings.csv')\n",
        "# ID Processing\n",
        "df['movieId'] = 'mov'+df['movieId'].astype(str)\n",
        "df['userId'] = 'user'+df['userId'].astype(str)\n",
        "# Label for Classification\n",
        "df['rating_class'] = df['rating'].apply(lambda x: 1.0 if x > 2.5 else 0.0)\n",
        "# Selecting Relevant Columns\n",
        "df = df[['userId','movieId','rating_class']]\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "_4aJVGsxebOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "movie_encoder = preprocessing.LabelEncoder()\n",
        "user_encoder = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "EpBAbFI_loIy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_encoder.fit(df['movieId'].tolist())\n",
        "user_encoder.fit(df['userId'].tolist())\n",
        "len(movie_encoder.classes_), len(user_encoder.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfSau9-qloFf",
        "outputId": "9c424411-b5b3-4ee8-d58f-b71892c138b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9724, 610)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating Positive and Negative Samples\n",
        "df_neg = df[df['rating_class']==0.0]\n",
        "df_pos = df[df['rating_class']==1.0]\n",
        "\n",
        "neg_data = dict()\n",
        "pos_data = dict()\n",
        "\n",
        "# Collecting Negative Samples:\n",
        "for idx, row in tqdm(df_neg.iterrows()):\n",
        "  if user_encoder.transform([row['userId']])[0] not in neg_data:\n",
        "    neg_data[user_encoder.transform([row['userId']])[0]] = list(movie_encoder.transform([row['movieId']]))\n",
        "  else:\n",
        "    neg_data[user_encoder.transform([row['userId']])[0]].extend(list(movie_encoder.transform([row['movieId']])))\n",
        "\n",
        "# Collecting Positive Samples:\n",
        "for idx, row in tqdm(df_neg.iterrows()):\n",
        "  if user_encoder.transform([row['userId']])[0] not in pos_data:\n",
        "    pos_data[user_encoder.transform([row['userId']])[0]] = list(movie_encoder.transform([row['movieId']]))\n",
        "  else:\n",
        "    pos_data[user_encoder.transform([row['userId']])[0]].extend(list(movie_encoder.transform([row['movieId']])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzVQG_wReUp8",
        "outputId": "c6b45480-0af6-43e1-d54d-cb0124b19efe"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19073it [03:22, 94.25it/s] \n",
            "19073it [03:21, 94.49it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(neg_data.items())[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US19i6erkuyv",
        "outputId": "f3fc039e-ab37-4d20-d82f-b9d085079423"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, [769, 2688, 2765, 2817, 3087, 3899]),\n",
              " (111, [9345, 543]),\n",
              " (222,\n",
              "  [3789,\n",
              "   6142,\n",
              "   7321,\n",
              "   7664,\n",
              "   8036,\n",
              "   9328,\n",
              "   364,\n",
              "   479,\n",
              "   860,\n",
              "   894,\n",
              "   980,\n",
              "   2482,\n",
              "   2540,\n",
              "   2550,\n",
              "   2566,\n",
              "   2856,\n",
              "   3946,\n",
              "   4762,\n",
              "   5932,\n",
              "   7114,\n",
              "   8071])]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting environment variables\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
        "\n",
        "# you will need a V100 or A100 to run tutorial as as! Colab gives users access to V100 and A100 GPUs\n",
        "# If you do not have access to those GPUs use “gloo” backend and run on CPU\n",
        "dist.init_process_group(backend=\"nccl\")"
      ],
      "metadata": {
        "id": "STqX9mHaenIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommendationModel(torch.nn.Module):\n",
        "    def __init__(self, ) -> None:\n",
        "        super(RecommendationModel, self).__init__()\n",
        "        self.embedding_collection = torchrec.EmbeddingBagCollection(\n",
        "                                    device=\"meta\",\n",
        "                                    tables=[\n",
        "                                        torchrec.EmbeddingBagConfig(\n",
        "                                            name=\"userid_table\",\n",
        "                                            embedding_dim=64,\n",
        "                                            num_embeddings=len(user_encoder.classes_),\n",
        "                                            feature_names=[\"userid\"],\n",
        "                                            pooling=torchrec.PoolingType.SUM\n",
        "                                        ),\n",
        "                                        torchrec.EmbeddingBagConfig(\n",
        "                                            name=\"movies_seen_table\",\n",
        "                                            embedding_dim=64,\n",
        "                                            num_embeddings=len(movie_encoder.classes_),\n",
        "                                            feature_names=[\"movies_seen\"],\n",
        "                                            pooling=torchrec.PoolingType.SUM\n",
        "                                        )\n",
        "                                    ]\n",
        "                                )\n",
        "        self.model = torchrec.distributed.DistributedModelParallel(self.embedding_collection, device=torch.device(\"cuda\"))\n",
        "        print(self.model.plan)\n",
        "        self.linear_layer = torch.nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        userids = []\n",
        "        movies_seen = []\n",
        "        for row in inputs:\n",
        "          userids.append(row[0])\n",
        "          movies_seen.append(row[1])\n",
        "\n",
        "        values = copy.deepcopy(userids)\n",
        "        lengths = [1]*len(values)\n",
        "        for movie_list in movies_seen:\n",
        "          values.extend(movie_list)\n",
        "          lengths.append(len(movie_list))\n",
        "\n",
        "        kjt = torchrec.KeyedJaggedTensor(\n",
        "                  keys = [\"userid\",\"movies_seen\"],\n",
        "                  values = torch.tensor(values).cuda(),\n",
        "                  lengths = torch.tensor(lengths, dtype=torch.int64).cuda(),\n",
        "              )\n",
        "\n",
        "        pooled_embeddings = self.model(kjt).to_dict()\n",
        "        out = pooled_embeddings['userid'] * pooled_embeddings['movies_seen']\n",
        "        out = out.to('cpu')\n",
        "        out = torch.nn.functional.sigmoid(self.linear_layer(out))\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "b-NRZBROXqke"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rec_model = RecommendationModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU2d1vWLbKCT",
        "outputId": "c488308b-ee1c-4e1e-d9dd-7b48dbe608b5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Could not determine LOCAL_WORLD_SIZE from environment, falling back to WORLD_SIZE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module: \n",
            "\n",
            "      param       | sharding type | compute kernel | ranks\n",
            "----------------- | ------------- | -------------- | -----\n",
            "userid_table      | table_wise    | fused          | [0]  \n",
            "movies_seen_table | table_wise    | fused          | [0]  \n",
            "\n",
            "      param       | shard offsets | shard sizes |   placement  \n",
            "----------------- | ------------- | ----------- | -------------\n",
            "userid_table      | [0, 0]        | [610, 64]   | rank:0/cuda:0\n",
            "movies_seen_table | [0, 0]        | [9724, 64]  | rank:0/cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = list(neg_data.items())[:3]"
      ],
      "metadata": {
        "id": "5LTtykM5muXE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = rec_model(sample)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb_Yp_BabMo8",
        "outputId": "eb12bf9b-bb84-4a58-8051-feb2001a6127"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4706],\n",
            "        [0.4705],\n",
            "        [0.4706]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchrec.optim.apply_optimizer_in_backward import apply_optimizer_in_backward\n",
        "from torchrec.optim.keyed import KeyedOptimizerWrapper\n",
        "from torchrec.optim.optimizers import in_backward_optimizer_filter\n",
        "\n",
        "apply_optimizer_in_backward(\n",
        "    optimizer_class=torch.optim.SGD,\n",
        "    params=rec_model.embedding_collection.parameters(),\n",
        "    optimizer_kwargs={\"lr\": 0.02},\n",
        ")"
      ],
      "metadata": {
        "id": "MYR8DWaAfhwU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.NLLLoss()\n",
        "torchrec_optim = KeyedOptimizerWrapper(\n",
        "    {k: v for k, v in dict(in_backward_optimizer_filter(\n",
        "        rec_model.named_parameters())).items()},\n",
        "    lambda params: torch.optim.SGD(params, lr=0.01, momentum=0.0),\n",
        ")"
      ],
      "metadata": {
        "id": "5rTQuwBCZ-dF"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion(out, torch.Tensor([0,0,0]).long())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZgjrcuJoT5h",
        "outputId": "6f999c42-e899-4c56-cd93-a33f3ca9e8b2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.4706, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchrec model forward\n",
        "torchrec_optim.zero_grad()\n",
        "output = rec_model(sample)\n",
        "label = torch.Tensor([0,0,0]).long()\n",
        "torchrec_loss = criterion(output, label)\n",
        "torchrec_loss.backward()\n",
        "torchrec_optim.step()\n"
      ],
      "metadata": {
        "id": "xrt9DpVDoBtW"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchrec_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLsiFYU9olkS",
        "outputId": "3c42e617-57ef-427e-f5cf-4c8e99919752"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.4706, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PlobgI8uonM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}